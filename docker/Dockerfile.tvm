# docker build --rm -t neuriplo:tvm -f docker/Dockerfile.tvm .
# docker run --rm neuriplo:tvm

# Stage 1: Base dependencies
ARG UBUNTU_VERSION=24.04
FROM ubuntu:${UBUNTU_VERSION} AS base_dependencies

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV HOME=/root
ENV DEPENDENCIES_DIR=${HOME}/dependencies
ENV TVM_DIR=${DEPENDENCIES_DIR}/tvm

# Install system dependencies including LLVM for TVM
RUN apt-get update && apt-get upgrade -y && \
    apt-get install -y \
    cmake=3.* \
    build-essential \
    pkg-config \
    wget \
    git \
    unzip \
    curl \
    python3 \
    python3-pip \
    python3-dev \
    python3-venv \
    libopenblas-dev \
    libgoogle-glog-dev \
    ninja-build \
    libopencv-dev \
    libopencv-contrib-dev \
    llvm-18-dev \
    libtinfo-dev \
    zlib1g-dev \
    libedit-dev \
    libxml2-dev \
    && rm -rf /var/lib/apt/lists/*

# Build and install GTest
# Build and install GTest manually
RUN git clone https://github.com/google/googletest.git -b v1.14.0 /usr/src/gtest-build && \
    cd /usr/src/gtest-build && \
    cmake -DCMAKE_INSTALL_PREFIX=/usr/local -DBUILD_GMOCK=ON . && \
    make && \
    make install && \
    cd / && rm -rf /usr/src/gtest-build

# Stage 2: Install TVM
FROM base_dependencies AS tvm_install

# Set TVM version (should match versions.env)
ENV TVM_VERSION=0.22.0

# Clone and build TVM
RUN mkdir -p ${TVM_DIR} && \
    cd ${DEPENDENCIES_DIR} && \
    git clone --recursive https://github.com/apache/tvm tvm && \
    cd tvm && \
    git fetch --tags && \
    git checkout v${TVM_VERSION} && \
    git submodule update --init --recursive

# Configure and build TVM
RUN cd ${TVM_DIR} && \
    mkdir -p build && \
    cd build && \
    cmake .. \
        -DCMAKE_BUILD_TYPE=Release \
        -DUSE_LLVM=/usr/lib/llvm-18/bin/llvm-config \
        -DUSE_CUDA=OFF \
        -DUSE_OPENCL=OFF \
        -DUSE_VULKAN=OFF \
        -DUSE_METAL=OFF \
        -DUSE_ROCM=OFF \
        -DUSE_RTTI=ON \
        -DUSE_GRAPH_EXECUTOR=ON \
        -DUSE_PROFILER=ON \
        -DUSE_RELAY_DEBUG=ON \
        -DBUILD_SHARED_LIBS=ON \
        -DINSTALL_DEV=ON && \
    make -j$(nproc) && \
    make install

# Install Python dependencies first
RUN pip3 install --break-system-packages \
        numpy \
        decorator \
        attrs \
        tornado \
        psutil \
        'xgboost>=1.1.0' \
        cloudpickle \
        onnx \
        onnxruntime

# Install tvm-ffi (required for TVM Python bindings)
RUN cd ${TVM_DIR}/3rdparty/tvm-ffi && \
    pip3 install --break-system-packages .

# Install TVM Python package
RUN cd ${TVM_DIR}/python && \
    pip3 install --break-system-packages -e .

# Verify TVM installation
RUN export TVM_HOME=${TVM_DIR} && \
    export PYTHONPATH=${TVM_DIR}/python:${PYTHONPATH} && \
    export LD_LIBRARY_PATH=${TVM_DIR}/build:${LD_LIBRARY_PATH} && \
    test -f ${TVM_DIR}/build/libtvm_runtime.so && \
    test -f ${TVM_DIR}/build/libtvm.so && \
    python3 -c "import tvm; print('TVM version:', tvm.__version__)"

# Set TVM environment variables
ENV TVM_HOME=${TVM_DIR}
ENV PYTHONPATH=${TVM_DIR}/python
ENV LD_LIBRARY_PATH=${TVM_DIR}/build

# Stage 3: Download and compile models with TVM
FROM tvm_install AS model_compiler

# Create model directory
RUN mkdir -p /opt/models

# Download ResNet18 ONNX model from ONNX Model Zoo
RUN wget -O /opt/models/resnet18.onnx \
    https://github.com/onnx/models/raw/refs/heads/main/validated/vision/classification/resnet/model/resnet18-v1-7.onnx

# Verify the model was downloaded
RUN ls -la /opt/models/ && \
    echo "ResNet18 ONNX model downloaded successfully"

# Debug: Check TVM header files structure for CMake validation  
RUN echo "=== TVM runtime headers ===" && \
    find ${TVM_DIR}/include/tvm/runtime -name "*.h" | sort && \
    echo "=== DLPack structure ===" && \
    find ${TVM_DIR}/3rdparty -name "dlpack.h" && \
    echo "=== 3rdparty directory structure ===" && \
    ls -la ${TVM_DIR}/3rdparty/

# Fix DLPack header issue by creating symlink if needed
RUN if [ ! -f "${TVM_DIR}/3rdparty/dlpack/dlpack.h" ] && [ -f "${TVM_DIR}/3rdparty/dlpack/include/dlpack/dlpack.h" ]; then \
        mkdir -p ${TVM_DIR}/3rdparty/dlpack && \
        ln -sf ${TVM_DIR}/3rdparty/dlpack/include/dlpack/dlpack.h ${TVM_DIR}/3rdparty/dlpack/dlpack.h; \
    fi

# Create TVM model compilation script
RUN cat > /opt/models/test_tvm_import.py << 'EOF'
#!/usr/bin/env python3
"""Test TVM imports to see what's available"""
import tvm
print("TVM version:", tvm.__version__)
print("Available modules:")
try:
    from tvm import relay
    print("✓ relay module available")
except ImportError as e:
    print("✗ relay import failed:", e)

try:
    from tvm import relax
    print("✓ relax module available")  
except ImportError as e:
    print("✗ relax import failed:", e)

print("TVM modules:", [x for x in dir(tvm) if not x.startswith('_')])
EOF

RUN python3 /opt/models/test_tvm_import.py

RUN cat > /opt/models/compile_model.py << 'EOF'
#!/usr/bin/env python3
"""Compile ONNX model to TVM format using TVM 0.22.0 API"""
import os
import onnx
import tvm
import tvm.relax as relax
from tvm.relax.frontend.onnx import from_onnx

print("TVM version:", tvm.__version__)

# Load ONNX model
print("Loading ONNX model...")
onnx_model = onnx.load("/opt/models/resnet18.onnx")

# Convert ONNX to TVM using the correct 0.22.0 API
print("Converting ONNX to Relax IR...")
mod = from_onnx(onnx_model, keep_params_in_input=True)
print("✓ Successfully converted using tvm.relax.frontend.onnx")

# Set target (CPU with LLVM)
target = tvm.target.Target("llvm")

# Build the module
print("Building TVM module...")
with tvm.transform.PassContext(opt_level=3):
    ex = relax.build(mod, target)

# Export compiled model
print("Exporting compiled model...")
ex.export_library("/opt/models/resnet18_tvm.so")

print("TVM compilation completed successfully!")
print(f"✓ Output: /opt/models/resnet18_tvm.so")
EOF

# Compile the model with TVM
RUN chmod +x /opt/models/compile_model.py && \
    python3 /opt/models/compile_model.py && \
    echo "Model compiled to TVM format successfully" && \
    ls -lh /opt/models/resnet18_tvm.so

# Stage 4: Build application
FROM model_compiler AS builder

WORKDIR /app

# Copy source code
COPY . .

# Build the project with TVM backend and tests enabled
RUN rm -rf build && \
    cmake -Bbuild -H. \
    -DDEFAULT_BACKEND=TVM \
    -DBUILD_INFERENCE_ENGINE_TESTS=ON \
    -DTVM_DIR=${TVM_DIR} \
    && cmake --build build --config Release -j$(nproc)

# Stage 5: Copy pre-compiled models
FROM builder AS model_generator

# Copy the compiled TVM model to test directory
WORKDIR /app/build/backends/tvm/test
RUN cp /opt/models/resnet18_tvm.so . && \
    echo "ResNet18 TVM model copied to test directory"

# Create model_path.txt file for the test
RUN echo "$(pwd)/resnet18_tvm.so" > model_path.txt && \
    echo "Model path file created: $(cat model_path.txt)"

# Stage 6: Final runtime image for testing
FROM tvm_install AS final

# Create non-root user
RUN useradd -m testuser && \
    mkdir -p /app && \
    chown -R testuser:testuser /app

# Copy built binaries and test files
COPY --from=model_generator --chown=testuser:testuser /app/build /app/build
COPY --from=model_generator --chown=testuser:testuser /app/backends/tvm/test /app/backends/tvm/test

# Copy TVM libraries and headers to final stage
COPY --from=tvm_install --chown=testuser:testuser ${TVM_DIR}/build /opt/tvm/build
COPY --from=tvm_install --chown=testuser:testuser ${TVM_DIR}/include /opt/tvm/include
COPY --from=tvm_install --chown=testuser:testuser ${TVM_DIR}/python /opt/tvm/python

# Set working directory to where the test files are located
WORKDIR /app/build/backends/tvm/test

# Switch to test user
USER testuser

# Set TVM environment variables
ENV TVM_HOME=/opt/tvm
ENV PYTHONPATH=/opt/tvm/python
ENV LD_LIBRARY_PATH=/app/build/lib:/opt/tvm/build

# Health check
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
    CMD test -f /app/build/lib/libneuriplo.so || exit 1

# Default command to run TVM tests
CMD ["./TVMInferTest"]
