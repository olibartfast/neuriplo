# docker build --rm -t neuriplo:tensorrt -f docker/Dockerfile.tensorrt .

# Stage 1: Cuda dependencies
ARG UBUNTU_VERSION=24.04
ARG NGC_CUDA_VERSION=13.0.0
FROM nvcr.io/nvidia/cuda:${NGC_CUDA_VERSION}-devel-ubuntu${UBUNTU_VERSION} as cuda_dependencies

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive

# Install system dependencies with version pinning
RUN apt-get update && apt-get upgrade -y && \
    apt-get install -y \
    cmake=3.* \
    build-essential=12.* \
    libopencv-dev \
    libgoogle-glog-dev \
    libgtest-dev \
    wget \
    git \
    && rm -rf /var/lib/apt/lists/*

COPY versions.env /tmp/versions.env

# Stage 2: Install TensorRT dependencies
FROM cuda_dependencies AS backend_dependencies

# Download and install TensorRT
RUN . /tmp/versions.env && \
    TRT_SHORT=$(echo ${TENSORRT_VERSION} | cut -d. -f1-3) && \
    wget --tries=3 --retry-connrefused \
    https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/${TRT_SHORT}/tars/TensorRT-${TENSORRT_VERSION}.Linux.x86_64-gnu.cuda-${CUDA_VERSION}.tar.gz \
    && tar -xzvf TensorRT-${TENSORRT_VERSION}.Linux.x86_64-gnu.cuda-${CUDA_VERSION}.tar.gz -C /opt \
    && rm TensorRT-${TENSORRT_VERSION}.Linux.x86_64-gnu.cuda-${CUDA_VERSION}.tar.gz \
    && ln -s /opt/TensorRT-${TENSORRT_VERSION} /opt/tensorrt

ENV TENSORRT_DIR=/opt/tensorrt
ENV LD_LIBRARY_PATH=${TENSORRT_DIR}/lib:${LD_LIBRARY_PATH:-}
ENV LIBRARY_PATH=${TENSORRT_DIR}/lib:${LIBRARY_PATH:-}
ENV CPATH=${TENSORRT_DIR}/include
ENV PATH=${TENSORRT_DIR}/bin:${PATH}

# Stage 3: Build application
FROM backend_dependencies AS builder

WORKDIR /app

# Copy source code
COPY . .

ARG BACKEND=TENSORRT

# Build the project
RUN . /tmp/versions.env && \
    rm -rf build && \
    cmake -Bbuild -H. \
    -DDEFAULT_BACKEND=${BACKEND} \
    -DTRT_VERSION=${TENSORRT_VERSION} \
    -DTENSORRT_DIR=${TENSORRT_DIR} \
    -DBUILD_INFERENCE_ENGINE_TESTS=ON \
    && cmake --build build --config Release \
    && ls -la /app/build # Check the output to find the library
    # you can add also:
    # && ls -la /app/build/lib
    # && ls -la /app/build/src

# Stage 4: Final runtime image
FROM backend_dependencies AS final

# Create non-root user
RUN useradd -m appuser && \
    mkdir -p /app/data && \
    mkdir -p /app/include && \
    mkdir -p /app/lib && \
    mkdir -p /app/test && \
    chown -R appuser:appuser /app

# Copy built library from builder stage (Adjust the paths if needed)
COPY --from=builder --chown=appuser:appuser /app/build/libneuriplo.so /app/lib/
# Copy test executables
COPY --from=builder --chown=appuser:appuser /app/build/backends/tensorrt/test/TensorRTInferTest /app/test/
# Copy test data files
COPY --from=builder --chown=appuser:appuser /app/backends/tensorrt/test/resnet18.engine /app/test/
COPY --from=builder --chown=appuser:appuser /app/backends/tensorrt/test/resnet18.onnx /app/test/
COPY --from=builder --chown=appuser:appuser /app/backends/tensorrt/test/generate_trt_engine.sh /app/test/
RUN chmod +x /app/test/generate_trt_engine.sh
# If you have a specific directory for public headers:
COPY --from=builder --chown=appuser:appuser /app/include /app/include
# Or, if headers are in the build directory (less common for libraries):
# COPY --from=builder --chown=appuser:appuser /app/build/path/to/headers /app/include

# Set working directory and user
WORKDIR /app
USER appuser

# Add volume for persistent data
VOLUME ["/app/data"]


# Set library path
ENV LD_LIBRARY_PATH=/app/lib:$LD_LIBRARY_PATH

# Health check (This might need adjustment for a library)
# You might want to check for the existence of the library instead
HEALTHCHECK --interval=30s --timeout=10s --retries=3 \
    CMD test -f /app/lib/libneuriplo.so || exit 1

# Default command (You probably don't need this for a library)
# ENTRYPOINT ["/app/neuriplo"]
# CMD ["--default-args"]